{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† TDNN + LSTM for Speech-to-Text using .flac Audio\n",
    "This notebook implements a basic speech recognition model using TDNN + LSTM + CTC loss.\n",
    "- Audio: `.flac` files\n",
    "- Features: Log-Mel spectrograms\n",
    "- Model: TDNN + LSTM\n",
    "- Loss: CTC\n",
    "\n",
    "Make sure you have the following files:\n",
    "- `.flac` audio files in a folder\n",
    "- A `transcripts.txt` with lines like: `filename transcription`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: librosa in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: filelock in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pycparser in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install Dependencies (if needed)\n",
    "!pip install torch torchaudio librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Imports and Settings\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import string\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CHARS = \" \" + string.ascii_lowercase + \"'\"\n",
    "char2idx = {c: i + 1 for i, c in enumerate(CHARS)}\n",
    "char2idx[\"<pad>\"] = 0\n",
    "idx2char = {i: c for c, i in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî§ Tokenizer\n",
    "def text_to_indices(text):\n",
    "    return torch.tensor([char2idx[c] for c in text.lower() if c in char2idx], dtype=torch.long)\n",
    "\n",
    "# üîä Feature Extraction\n",
    "def extract_features(waveform):\n",
    "    mel_spec = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE)(waveform)\n",
    "    log_mel_spec = torchaudio.transforms.AmplitudeToDB()(mel_spec)\n",
    "    return log_mel_spec.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, audio_dir, tsv_file):\n",
    "        # Read TSV file\n",
    "        with open(tsv_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        self.data = []\n",
    "        for line in lines:\n",
    "            # Split by tab and take only 1st and 3rd columns\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 3:  # Ensure we have all required columns\n",
    "                utt_id = parts[0]  # First column - utterance ID\n",
    "                transcription = parts[2]  # Third column - transcription\n",
    "                \n",
    "                # Construct full audio path \n",
    "                audio_path = os.path.join(audio_dir, f\"{utt_id}.flac\")\n",
    "                \n",
    "                if os.path.exists(audio_path):\n",
    "                    self.data.append((audio_path, transcription))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, text = self.data[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
    "        features = extract_features(waveform.squeeze(0))\n",
    "        target = text_to_indices(text)\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Collate Function\n",
    "def collate_fn(batch):\n",
    "    features, targets = zip(*batch)\n",
    "    input_lengths = [f.shape[0] for f in features]\n",
    "    target_lengths = [len(t) for t in targets]\n",
    "\n",
    "    features = pad_sequence(features, batch_first=True)\n",
    "    targets = pad_sequence(targets, batch_first=False)\n",
    "\n",
    "    return features, targets, torch.tensor(input_lengths), torch.tensor(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Model Definition\n",
    "class TDNN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.tdnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.tdnn(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Training Loop\n",
    "def train(model, dataloader, optimizer, epochs):\n",
    "    model.train()\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features, targets, input_lengths, target_lengths in dataloader:\n",
    "            features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(features)\n",
    "            log_probs = nn.functional.log_softmax(outputs, dim=-1)\n",
    "            loss = ctc_loss(log_probs.transpose(0, 1), targets, input_lengths, target_lengths)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cdfd8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ./00/ using hello00.tsv\n",
      "Found 715 valid audio-transcript pairs\n",
      "Initializing model with:\n",
      "- Input dim: 128\n",
      "- Hidden dim: 256\n",
      "- Output dim: 29\n",
      "- Device: cpu\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/switchblade/miniconda3/envs/sinha/lib/python3.9/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 16 at dimension 0, but got size 24 for argument #2 'targets' (while checking arguments for ctc_loss_allocate_outputs)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar2idx\u001b[39m\u001b[38;5;124m'\u001b[39m: char2idx,\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx2char\u001b[39m\u001b[38;5;124m'\u001b[39m: idx2char\n\u001b[1;32m     41\u001b[0m     }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msinhala_asr_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     10\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/sinha/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sinha/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/sinha/lib/python3.9/site-packages/torch/nn/modules/loss.py:1982\u001b[0m, in \u001b[0;36mCTCLoss.forward\u001b[0;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1977\u001b[0m     log_probs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     target_lengths: Tensor,\n\u001b[1;32m   1981\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_infinity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sinha/lib/python3.9/site-packages/torch/nn/functional.py:3079\u001b[0m, in \u001b[0;36mctc_loss\u001b[0;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n\u001b[1;32m   3068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3069\u001b[0m         ctc_loss,\n\u001b[1;32m   3070\u001b[0m         (log_probs, targets, input_lengths, target_lengths),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3077\u001b[0m         zero_infinity\u001b[38;5;241m=\u001b[39mzero_infinity,\n\u001b[1;32m   3078\u001b[0m     )\n\u001b[0;32m-> 3079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_infinity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 16 at dimension 0, but got size 24 for argument #2 'targets' (while checking arguments for ctc_loss_allocate_outputs)"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "audio_dir = \"./00/\"\n",
    "tsv_file = \"hello00.tsv\"\n",
    "\n",
    "print(f\"Loading dataset from {audio_dir} using {tsv_file}\")\n",
    "dataset = SpeechDataset(audio_dir, tsv_file)\n",
    "print(f\"Found {len(dataset)} valid audio-transcript pairs\")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,  # Reduced batch size for stability\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "input_dim = 128  # Number of mel frequency bins\n",
    "hidden_dim = 256\n",
    "output_dim = len(char2idx)  # Vocabulary size\n",
    "\n",
    "print(f\"Initializing model with:\")\n",
    "print(f\"- Input dim: {input_dim}\")\n",
    "print(f\"- Hidden dim: {hidden_dim}\") \n",
    "print(f\"- Output dim: {output_dim}\")\n",
    "print(f\"- Device: {DEVICE}\")\n",
    "\n",
    "model = TDNN_LSTM_Model(input_dim, hidden_dim, output_dim).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "print(\"\\nStarting training...\")\n",
    "try:\n",
    "    train(model, dataloader, optimizer, epochs=10)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'char2idx': char2idx,\n",
    "        'idx2char': idx2char\n",
    "    }, 'sinhala_asr_model.pth')\n",
    "    print(\"\\nModel saved to sinhala_asr_model.pth\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted. Saving current model state...\")\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'char2idx': char2idx,\n",
    "        'idx2char': idx2char\n",
    "    }, 'sinhala_asr_model_interrupted.pth')\n",
    "    print(\"Model saved to sinhala_asr_model_interrupted.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
