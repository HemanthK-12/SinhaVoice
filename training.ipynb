{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training A Neural-Network-Based Speech-To-Text Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after the processed.tsv is ready with audio paths, transcripts, tokens and token indices, we need to train a neural network based or transformer-based speech to text model.\n",
    "\n",
    "One of the examples of speech-to-text NN-based model is Wav2Vec 2.0 by Hugging Face. We will take this pre-trained model, which is best for speech-to-text , and train it on the __Large Sinhala ASR dataset__ in the /audio folder. Then, we see the trained model's performance and fine-tune it's parameters afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to give a __loss function__ to the model, which is like a way in which the model can learn from it's mistakes and one of the famous loss function is called Connectionist Temporal Classification (CTC).This helps the model learn even if the length of input and output don't match.So, when the model listens to a sentence and tries to guess the words, CTC helps it figure out how far off its guesses are from the correct words and guides it on how to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First\n",
    "We need to sample all of the audio to 16Hz because Wav2Vec 2.0 takes input of speech files in 16Hz, using torch audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/switchblade/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map:   5%|▌         | 7986/155970 [00:49<12:43, 193.76 examples/s] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "from datasets import Dataset, load_metric\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "# Load the TSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"./tsv_files/processed.tsv\", delimiter='\\t')\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Function to load and preprocess the audio\n",
    "def preprocess_audio(batch):\n",
    "    # Load the audio file\n",
    "    speech_array, sample_rate = sf.read(batch['audio_path'])\n",
    "    # Resample to 16kHz if necessary\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "    speech_array = resampler(torch.tensor(speech_array))\n",
    "    batch['speech'] = speech_array.numpy()\n",
    "    return batch\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "dataset = dataset.map(preprocess_audio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the pretrained Wav2Vec 2.0 model and processor.Model(Brain) does all of the learning, predictions and the neural network part while the Processor(Helper to Brain) takes care of the input audio feeding and decoding the output of the model acting as a medium btween us and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Load the pre-trained Wav2Vec2 model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\", vocab_size=len(open(\"vocabulary.txt\").readlines()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we tokenise the transcripts and map each of the token to the features found by the model in the audio.Here, the loss function will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(batch):\n",
    "    batch['input_values'] = processor(batch['speech'], sampling_rate=16000).input_values[0]\n",
    "    batch['labels'] = batch['token_indices']\n",
    "    return batch\n",
    "\n",
    "# Apply tokenization\n",
    "dataset = dataset.map(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all the parameters the pre-trained model needs to be trained on and let it train on the sinhala dataset. These can then be changed while fine-tuning it for the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./wav2vec2-finetuned\",\n",
    "  per_device_train_batch_size=8,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=3,\n",
    "  save_steps=500,\n",
    "  eval_steps=500,\n",
    "  logging_steps=100,\n",
    "  learning_rate=1e-4,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,  # Replace with a validation set if available\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finding the performance of the model is fairly easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure performance of the model based on 2 values : Word Error Rate and Character Error Rate.\n",
    "In Simple words,\n",
    "WER tells you how many words the model got wrong in its transcription.\n",
    "CER tells you how many characters the model got wrong in its transcription.\n",
    "\n",
    "#### WER \n",
    "WER is a metric that calculates the difference between the predicted text and the actual text at the word level and is computed by comparing the number of words that were incorrectly transcribed by the model to the total number of words in the reference (correct) transcript. __LOWER WER=MORE ACCURATE.__\n",
    "\n",
    "$\\text{WER} = \\frac{S + D + I}{N}$\n",
    "- **S** = Number of substitutions (wrong word instead of the correct one)\n",
    "- **D** = Number of deletions (missed words)\n",
    "- **I** = Number of insertions (extra words added)\n",
    "- **N** = Total number of words in the reference transcript\n",
    "\n",
    "#### CER\n",
    "Character Error Rate is same as WER but for individual characters and useful when the text contains a lot of short words, or when you want finer granularity in the error analysis. __LOWER CER=MORE ACCURATE.__\n",
    "$\\text{CER} = \\frac{S + D + I}{N}$\n",
    "- **S** = Number of substitutions (wrong character instead of the correct one)\n",
    "- **D** = Number of deletions (missed characters)\n",
    "- **I** = Number of insertions (extra characters added)\n",
    "- **N** = Total number of characters in the reference transcript\n",
    "\n",
    "​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WER metric\n",
    "wer_metric = load_metric(\"wer\")\n",
    "\n",
    "# Predict on the dataset\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions.argmax(-1)\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    # Compute WER\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=dataset['transcript'])\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Word Error Rate (WER): {results['eval_wer']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
